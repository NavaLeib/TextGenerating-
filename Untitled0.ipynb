{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNTukyR13Tt0SkcfpmiozHa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NavaLeib/TextGenerating-/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkZBan6-z_ZI"
      },
      "source": [
        "## First step : \n",
        "### extracting the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXpbde5k_ONh",
        "outputId": "736af82f-9199-4a03-9036-0359b3672ac0"
      },
      "source": [
        "!pip install feedparser\n",
        "\n",
        "import urllib.request\n",
        "import feedparser\n",
        "\n",
        "# Base api query url\n",
        "base_url = 'http://export.arxiv.org/api/query?';\n",
        "\n",
        "# Search parameters\n",
        "search_query = 'all:electron' # search for electron in all fields\n",
        "start = 0                     # retreive the first 5 results\n",
        "max_results = 10**4\n",
        "\n",
        "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
        "                                                     start,\n",
        "                                                     max_results)\n",
        "\n",
        "# perform a GET request using the base_url and query\n",
        "response = urllib.request.urlopen(base_url+query).read()\n",
        "\n",
        "# parse the response using feedparser\n",
        "feed = feedparser.parse(response)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.7/dist-packages (6.0.8)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCygoWCJ0VP8"
      },
      "source": [
        "### convert it into a list + dataframe "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZj127blp3uA"
      },
      "source": [
        "#coloums of interasts (maybe?)\n",
        "col=['title', 'summary', 'authors', 'arxiv_primary_category', 'tags']\n",
        "\n",
        "# Run through each entry, and fill the information into a list\n",
        "data_list=[]\n",
        "for c in col:\n",
        "  abstract_list=[]\n",
        "  for entry in feed.entries:\n",
        "    abstract_list.append(entry.get(c))\n",
        "  data_list.append(abstract_list)\n",
        "\n",
        "# convert into a panda dataframe (maybe more visible + have some pros I might need)\n",
        "import pandas as pd\n",
        "data_df = pd.DataFrame(data_list,index=col)\n",
        "data_df=data_df.T\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU5l6yin0uJU"
      },
      "source": [
        "data_df.to_csv('arXiv10.csv') "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "2cihhiBucihA",
        "outputId": "c54d44c6-1a98-42e6-b0e0-26337dea5ac6"
      },
      "source": [
        "data_df"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>authors</th>\n",
              "      <th>arxiv_primary_category</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Impact of Electron-Electron Cusp on Configurat...</td>\n",
              "      <td>The effect of the electron-electron cusp on th...</td>\n",
              "      <td>[{'name': 'David Prendergast'}, {'name': 'M. N...</td>\n",
              "      <td>{'term': 'cond-mat.str-el', 'scheme': 'http://...</td>\n",
              "      <td>[{'term': 'cond-mat.str-el', 'scheme': 'http:/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Electron thermal conductivity owing to collisi...</td>\n",
              "      <td>We calculate the thermal conductivity of elect...</td>\n",
              "      <td>[{'name': 'P. S. Shternin'}, {'name': 'D. G. Y...</td>\n",
              "      <td>{'term': 'astro-ph', 'scheme': 'http://arxiv.o...</td>\n",
              "      <td>[{'term': 'astro-ph', 'scheme': 'http://arxiv....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Electron pairing: from metastable electron pai...</td>\n",
              "      <td>Starting from the shell structure in atoms and...</td>\n",
              "      <td>[{'name': 'Guo-Qiang Hai'}, {'name': 'Ladir Câ...</td>\n",
              "      <td>{'term': 'cond-mat.str-el', 'scheme': 'http://...</td>\n",
              "      <td>[{'term': 'cond-mat.str-el', 'scheme': 'http:/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Electron Temperature Anisotropy and Electron B...</td>\n",
              "      <td>Electron temperature anisotropies and electron...</td>\n",
              "      <td>[{'name': 'Heyu Sun'}, {'name': 'Jinsong Zhao'...</td>\n",
              "      <td>{'term': 'physics.space-ph', 'scheme': 'http:/...</td>\n",
              "      <td>[{'term': 'physics.space-ph', 'scheme': 'http:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hamiltonian of a many-electron system with sin...</td>\n",
              "      <td>Based on the metastable electron-pair energy b...</td>\n",
              "      <td>[{'name': 'G. -Q. Hai'}, {'name': 'F. M. Peete...</td>\n",
              "      <td>{'term': 'cond-mat.supr-con', 'scheme': 'http:...</td>\n",
              "      <td>[{'term': 'cond-mat.supr-con', 'scheme': 'http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>Measurement of spin diffusion in semi-insulati...</td>\n",
              "      <td>We use optical transient-grating spectroscopy ...</td>\n",
              "      <td>[{'name': 'C. P. Weber'}, {'name': 'Craig A. B...</td>\n",
              "      <td>{'term': 'cond-mat.mtrl-sci', 'scheme': 'http:...</td>\n",
              "      <td>[{'term': 'cond-mat.mtrl-sci', 'scheme': 'http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>Role of electronic correlations in Ga</td>\n",
              "      <td>An extended around mean field (AMF) functional...</td>\n",
              "      <td>[{'name': 'Zhiyong Zhu'}, {'name': 'Xuhui Wang...</td>\n",
              "      <td>{'term': 'cond-mat.str-el', 'scheme': 'http://...</td>\n",
              "      <td>[{'term': 'cond-mat.str-el', 'scheme': 'http:/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>Effects of longer-range interactions on unconv...</td>\n",
              "      <td>We analyze the effect of the non-vanishing ran...</td>\n",
              "      <td>[{'name': 'S. Raghu'}, {'name': 'E. Berg'}, {'...</td>\n",
              "      <td>{'term': 'cond-mat.supr-con', 'scheme': 'http:...</td>\n",
              "      <td>[{'term': 'cond-mat.supr-con', 'scheme': 'http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>Mapping spin-polarised transitions with atomic...</td>\n",
              "      <td>The coupling between Angstrom-sized electron p...</td>\n",
              "      <td>[{'name': 'Peter Schattschneider'}, {'name': '...</td>\n",
              "      <td>{'term': 'cond-mat.mes-hall', 'scheme': 'http:...</td>\n",
              "      <td>[{'term': 'cond-mat.mes-hall', 'scheme': 'http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>On possibility of measurement of the electron ...</td>\n",
              "      <td>The possibility of the precise measurement of ...</td>\n",
              "      <td>[{'name': 'R. A. Melikian'}]</td>\n",
              "      <td>{'term': 'physics.acc-ph', 'scheme': 'http://a...</td>\n",
              "      <td>[{'term': 'physics.acc-ph', 'scheme': 'http://...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  ...                                               tags\n",
              "0     Impact of Electron-Electron Cusp on Configurat...  ...  [{'term': 'cond-mat.str-el', 'scheme': 'http:/...\n",
              "1     Electron thermal conductivity owing to collisi...  ...  [{'term': 'astro-ph', 'scheme': 'http://arxiv....\n",
              "2     Electron pairing: from metastable electron pai...  ...  [{'term': 'cond-mat.str-el', 'scheme': 'http:/...\n",
              "3     Electron Temperature Anisotropy and Electron B...  ...  [{'term': 'physics.space-ph', 'scheme': 'http:...\n",
              "4     Hamiltonian of a many-electron system with sin...  ...  [{'term': 'cond-mat.supr-con', 'scheme': 'http...\n",
              "...                                                 ...  ...                                                ...\n",
              "1995  Measurement of spin diffusion in semi-insulati...  ...  [{'term': 'cond-mat.mtrl-sci', 'scheme': 'http...\n",
              "1996              Role of electronic correlations in Ga  ...  [{'term': 'cond-mat.str-el', 'scheme': 'http:/...\n",
              "1997  Effects of longer-range interactions on unconv...  ...  [{'term': 'cond-mat.supr-con', 'scheme': 'http...\n",
              "1998  Mapping spin-polarised transitions with atomic...  ...  [{'term': 'cond-mat.mes-hall', 'scheme': 'http...\n",
              "1999  On possibility of measurement of the electron ...  ...  [{'term': 'physics.acc-ph', 'scheme': 'http://...\n",
              "\n",
              "[2000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liF3C_P68jTs"
      },
      "source": [
        "### tokenizing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL1_OauX_O5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0605c1d1-45a8-440e-e958-6a9cf6c756cc"
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (4.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrBRUil1zsps"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#taking just the titles (data_list[0]). (maybe to use the summary instaed?)\n",
        "# using lower case. removing extra spaces and '\\n ' \n",
        "doc=[nlp.tokenizer(text.lower().replace('\\n ','').strip()) for text in data_list[1]]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INkanj23b4oz"
      },
      "source": [
        "for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeOuK7w6XZa0",
        "outputId": "c2d577ac-9ef0-4713-fe6b-2113a49d561a"
      },
      "source": [
        "II=5;\n",
        "print([token.rank for token in doc[II]])\n",
        "print([token.lex_id for token in doc[II]])\n",
        "print([token.text for token in doc[II]])\n",
        "print([nlp.vocab.strings[token.text] for token in doc[II]])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[964, 244, 15686, 33, 19136, 7, 15686, 33, 15686, 358821, 3358, 5, 0, 3, 255, 1422, 33, 6810, 29900, 57, 4085, 17115, 2, 3, 3328, 11, 1754, 3500, 1, 280, 0, 58, 26948, 11, 28, 4123, 42, 15686, 41, 7, 18403, 22, 21514, 655, 197, 0, 2399, 197, 0, 125253, 2, 7, 15622, 8, 3, 2431, 15686, 33, 15686, 358821, 13, 0, 624, 235, 3, 15686, 4892, 1347, 5, 2179, 6, 583, 255, 1422, 33, 6810, 0, 4892, 39120, 42, 290, 21514, 1, 3363, 15686, 33, 19136, 358821, 2, 15686, 33, 15686, 358821, 46, 28, 0, 2179, 17785, 8, 51, 21514, 60, 5, 3, 4014, 15686, 1077, 1056, 1, 3, 0, 4014, 420, 18403, 1077, 1196, 20, 3, 2818, 331, 3, 1680, 8, 0, 3, 36338, 15686, 7, 3, 29737, 18403, 2, 7, 31, 4510, 6, 22859, 0, 16, 58, 2901, 19726, 1077, 1833, 16, 3, 1274, 8, 45133, 8, 3, 18990, 0, 13604, 1, 70, 9278, 3, 589, 1291, 8, 31266, 2149, 2, 6528, 7810, 80, 0, 7, 309, 0, 12, 3, 14295, 670, 170, 3505, 125253, 13, 3, 7810, 255, 1422, 33, 6810, 4892, 11, 0, 2693, 16123, 16, 80, 3, 15622, 8, 15686, 33, 15686, 358821, 1, 0, 1737, 2, 3, 220, 833, 15686, 4892, 9888, 214, 6, 208518, 0, 36788, 8, 3, 255, 1422, 33, 6810, 4892, 2, 287, 6, 1921, 33, 1688, 12, 2710, 244, 0, 15686, 33, 19136, 7, 15686, 33, 15686, 973, 2, 76, 6, 1843, 2354, 34638, 0, 6988, 197, 0, 136, 3, 949, 57, 15686, 17913, 1077, 197, 1700, 659, 1947, 197, 125253, 5, 197, 1700, 0, 659, 228, 197, 470798, 1, 747, 2, 3, 373, 8, 2514, 30919, 13, 3, 9888, 15686, 0, 4892, 11, 28, 4511, 5, 2914, 686, 40, 28, 106, 2901, 19726, 1077, 0, 1702, 1]\n",
            "[964, 244, 15686, 33, 19136, 7, 15686, 33, 15686, 358821, 3358, 5, 0, 3, 255, 1422, 33, 6810, 29900, 57, 4085, 17115, 2, 3, 3328, 11, 1754, 3500, 1, 280, 0, 58, 26948, 11, 28, 4123, 42, 15686, 41, 7, 18403, 22, 21514, 655, 197, 0, 2399, 197, 0, 125253, 2, 7, 15622, 8, 3, 2431, 15686, 33, 15686, 358821, 13, 0, 624, 235, 3, 15686, 4892, 1347, 5, 2179, 6, 583, 255, 1422, 33, 6810, 0, 4892, 39120, 42, 290, 21514, 1, 3363, 15686, 33, 19136, 358821, 2, 15686, 33, 15686, 358821, 46, 28, 0, 2179, 17785, 8, 51, 21514, 60, 5, 3, 4014, 15686, 1077, 1056, 1, 3, 0, 4014, 420, 18403, 1077, 1196, 20, 3, 2818, 331, 3, 1680, 8, 0, 3, 36338, 15686, 7, 3, 29737, 18403, 2, 7, 31, 4510, 6, 22859, 0, 16, 58, 2901, 19726, 1077, 1833, 16, 3, 1274, 8, 45133, 8, 3, 18990, 0, 13604, 1, 70, 9278, 3, 589, 1291, 8, 31266, 2149, 2, 6528, 7810, 80, 0, 7, 309, 0, 12, 3, 14295, 670, 170, 3505, 125253, 13, 3, 7810, 255, 1422, 33, 6810, 4892, 11, 0, 2693, 16123, 16, 80, 3, 15622, 8, 15686, 33, 15686, 358821, 1, 0, 1737, 2, 3, 220, 833, 15686, 4892, 9888, 214, 6, 208518, 0, 36788, 8, 3, 255, 1422, 33, 6810, 4892, 2, 287, 6, 1921, 33, 1688, 12, 2710, 244, 0, 15686, 33, 19136, 7, 15686, 33, 15686, 973, 2, 76, 6, 1843, 2354, 34638, 0, 6988, 197, 0, 136, 3, 949, 57, 15686, 17913, 1077, 197, 1700, 659, 1947, 197, 125253, 5, 197, 1700, 0, 659, 228, 197, 470798, 1, 747, 2, 3, 373, 8, 2514, 30919, 13, 3, 9888, 15686, 0, 4892, 11, 28, 4511, 5, 2914, 686, 40, 28, 106, 2901, 19726, 1077, 0, 1702, 1]\n",
            "['although', 'both', 'electron', '-', 'ion', 'and', 'electron', '-', 'electron', 'bremsstrahlung', 'contribute', 'to', '\\n', 'the', 'hard', 'x', '-', 'ray', 'emission', 'from', 'solar', 'flares', ',', 'the', 'latter', 'is', 'normally', 'ignored', '.', 'such', '\\n', 'an', 'omission', 'is', 'not', 'justified', 'at', 'electron', '(', 'and', 'photon', ')', 'energies', 'above', '$', '\\\\sim', '300', '$', '\\n', 'kev', ',', 'and', 'inclusion', 'of', 'the', 'additional', 'electron', '-', 'electron', 'bremsstrahlung', 'in', '\\n', 'general', 'makes', 'the', 'electron', 'spectrum', 'required', 'to', 'produce', 'a', 'given', 'hard', 'x', '-', 'ray', '\\n', 'spectrum', 'steeper', 'at', 'high', 'energies', '.', 'unlike', 'electron', '-', 'ion', 'bremsstrahlung', ',', 'electron', '-', 'electron', 'bremsstrahlung', 'can', 'not', '\\n', 'produce', 'photons', 'of', 'all', 'energies', 'up', 'to', 'the', 'maximum', 'electron', 'energy', 'involved', '.', 'the', '\\n', 'maximum', 'possible', 'photon', 'energy', 'depends', 'on', 'the', 'angle', 'between', 'the', 'direction', 'of', '\\n', 'the', 'emitting', 'electron', 'and', 'the', 'emitted', 'photon', ',', 'and', 'this', 'suggests', 'a', 'diagnostic', '\\n', 'for', 'an', 'upper', 'cutoff', 'energy', 'and/or', 'for', 'the', 'degree', 'of', 'beaming', 'of', 'the', 'accelerated', '\\n', 'electrons', '.', 'we', 'analyze', 'the', 'large', 'event', 'of', 'january', '17', ',', '2005', 'observed', 'by', 'rhessi', 'and', 'show', '\\n', 'that', 'the', 'upward', 'break', 'around', '400', 'kev', 'in', 'the', 'observed', 'hard', 'x', '-', 'ray', 'spectrum', 'is', '\\n', 'naturally', 'accounted', 'for', 'by', 'the', 'inclusion', 'of', 'electron', '-', 'electron', 'bremsstrahlung', '.', '\\n', 'indeed', ',', 'the', 'mean', 'source', 'electron', 'spectrum', 'recovered', 'through', 'a', 'regularized', '\\n', 'inversion', 'of', 'the', 'hard', 'x', '-', 'ray', 'spectrum', ',', 'using', 'a', 'cross', '-', 'section', 'that', 'includes', 'both', '\\n', 'electron', '-', 'ion', 'and', 'electron', '-', 'electron', 'terms', ',', 'has', 'a', 'relatively', 'constant', 'spectral', '\\n', 'index', '$', '\\\\delta$', 'over', 'the', 'range', 'from', 'electron', 'kinetic', 'energy', '$', 'e', '=', '200', '$', 'kev', 'to', '$', 'e', '\\n', '=', '1', '$', 'mev', '.', 'however', ',', 'the', 'level', 'of', 'detail', 'discernible', 'in', 'the', 'recovered', 'electron', '\\n', 'spectrum', 'is', 'not', 'sufficient', 'to', 'determine', 'whether', 'or', 'not', 'any', 'upper', 'cutoff', 'energy', '\\n', 'exists', '.']\n",
            "[343236316598008647, 7111508780595485950, 14911849430818137050, 9153284864653046197, 10748144119362648261, 2283656566040971221, 14911849430818137050, 9153284864653046197, 14911849430818137050, 5074391312506727947, 4511972451533797185, 3791531372978436496, 962983613142996970, 7425985699627899538, 5791351258821946298, 11123243248953317070, 9153284864653046197, 11428735203161385371, 7093072741639743635, 7831658034963690409, 3825196732376443040, 54522159426843760, 2593208677638477497, 7425985699627899538, 12804428435025074674, 3411606890003347522, 7401590555851523407, 13226335619999904025, 12646065887601541794, 13040105543478938413, 962983613142996970, 15099054000809333061, 12999855072149956216, 3411606890003347522, 447765159362469301, 5214226777537131638, 11667289587015813222, 14911849430818137050, 12638816674900267446, 2283656566040971221, 11239151029036873159, 3842344029291005339, 10745017010001694462, 12552628610781381849, 11283501755624150392, 1943680731549961342, 10429391924842734322, 11283501755624150392, 962983613142996970, 11107802967029525043, 2593208677638477497, 2283656566040971221, 190713507892190644, 886050111519832510, 7425985699627899538, 2629337523440010198, 14911849430818137050, 9153284864653046197, 14911849430818137050, 5074391312506727947, 3002984154512732771, 962983613142996970, 4476931165537661438, 13268885963146728493, 7425985699627899538, 14911849430818137050, 15872557144678396703, 2757536088714772928, 3791531372978436496, 11226362163621696944, 11901859001352538922, 15718315682364332688, 5791351258821946298, 11123243248953317070, 9153284864653046197, 11428735203161385371, 962983613142996970, 15872557144678396703, 2141670893418929297, 11667289587015813222, 8587113882175654237, 10745017010001694462, 12646065887601541794, 17472408549241926372, 14911849430818137050, 9153284864653046197, 10748144119362648261, 5074391312506727947, 2593208677638477497, 14911849430818137050, 9153284864653046197, 14911849430818137050, 5074391312506727947, 6635067063807956629, 447765159362469301, 962983613142996970, 11226362163621696944, 12371981325360525048, 886050111519832510, 13409319323822384369, 10745017010001694462, 2199259611705938403, 3791531372978436496, 7425985699627899538, 3862353238627587807, 14911849430818137050, 13079260030086073766, 16516520583231350447, 12646065887601541794, 7425985699627899538, 962983613142996970, 3862353238627587807, 1322442146463163273, 11239151029036873159, 13079260030086073766, 13944486046246046782, 5640369432778651323, 7425985699627899538, 8120899231236211520, 7508752285157982505, 7425985699627899538, 895834437038626927, 886050111519832510, 962983613142996970, 7425985699627899538, 11876755393662243163, 14911849430818137050, 2283656566040971221, 7425985699627899538, 11102617797775814689, 11239151029036873159, 2593208677638477497, 2283656566040971221, 1995909169258310477, 17342258809082567406, 11901859001352538922, 15614751325349280342, 962983613142996970, 16037325823156266367, 15099054000809333061, 3470900665073696637, 16845752617788871882, 13079260030086073766, 8332542706549259529, 16037325823156266367, 7425985699627899538, 8862567407865235748, 886050111519832510, 10100700906100211147, 886050111519832510, 7425985699627899538, 10864296466113066468, 962983613142996970, 4005043705408165069, 12646065887601541794, 16064069575701507746, 16995200471930577090, 7425985699627899538, 2751841902330220293, 16065740214838660377, 886050111519832510, 11810173174735819410, 6675425533856447351, 2593208677638477497, 17512444208610982826, 9682409757803690822, 16764210730586636600, 4913128208665527168, 2283656566040971221, 1916734850589852068, 962983613142996970, 4380130941430378203, 7425985699627899538, 16729869390353301496, 5527797886271786622, 3194226484742107227, 12495206808265140655, 11107802967029525043, 3002984154512732771, 7425985699627899538, 9682409757803690822, 5791351258821946298, 11123243248953317070, 9153284864653046197, 11428735203161385371, 15872557144678396703, 3411606890003347522, 962983613142996970, 11756612840599052966, 17571482490404966029, 16037325823156266367, 16764210730586636600, 7425985699627899538, 190713507892190644, 886050111519832510, 14911849430818137050, 9153284864653046197, 14911849430818137050, 5074391312506727947, 12646065887601541794, 962983613142996970, 8426076641132451626, 2593208677638477497, 7425985699627899538, 15580274710609099813, 9032917268300750242, 14911849430818137050, 15872557144678396703, 16285807339684619333, 18216413589307435838, 11901859001352538922, 7488353061408466552, 962983613142996970, 1780553328419086513, 886050111519832510, 7425985699627899538, 5791351258821946298, 11123243248953317070, 9153284864653046197, 11428735203161385371, 15872557144678396703, 2593208677638477497, 16421957100465448365, 11901859001352538922, 8734324568794052990, 9153284864653046197, 14418829838670935302, 4380130941430378203, 14932704014687019645, 7111508780595485950, 962983613142996970, 14911849430818137050, 9153284864653046197, 10748144119362648261, 2283656566040971221, 14911849430818137050, 9153284864653046197, 14911849430818137050, 6225537969047103320, 2593208677638477497, 1248239241591158246, 11901859001352538922, 17496422778774358763, 12835739328207984459, 3557956240084592399, 962983613142996970, 4791143286560280626, 11283501755624150392, 13612230212947673515, 5456543204961066030, 7425985699627899538, 9780120844974374175, 7831658034963690409, 14911849430818137050, 18014763166000425480, 13079260030086073766, 11283501755624150392, 1720370409040345145, 11162055469987148383, 4266673471014057460, 11283501755624150392, 11107802967029525043, 3791531372978436496, 11283501755624150392, 1720370409040345145, 962983613142996970, 11162055469987148383, 5533571732986600803, 11283501755624150392, 10701332063295951183, 12646065887601541794, 17682826258315136684, 2593208677638477497, 7425985699627899538, 15060127769916968652, 886050111519832510, 3706369497718032859, 10467570206039941982, 3002984154512732771, 7425985699627899538, 16285807339684619333, 14911849430818137050, 962983613142996970, 15872557144678396703, 3411606890003347522, 447765159362469301, 7448676634580798508, 3791531372978436496, 13750990675998287868, 4099315622432746663, 3740602843040177340, 447765159362469301, 13148361048351484388, 3470900665073696637, 16845752617788871882, 13079260030086073766, 962983613142996970, 13429073107707679016, 12646065887601541794]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmDuJLXd4bdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b47066ce-979c-42d4-b599-95318219bc81"
      },
      "source": [
        "# Words_vec= words in the text \n",
        "# Vocab = unique words in the text\n",
        "\n",
        "#import numpy as np\n",
        "\n",
        "#Words=[]\n",
        "#Words_id=[]\n",
        "#Max_Length=30;\n",
        "#Words_vec= np.empty([max_results,Max_Length],dtype='int')\n",
        "\n",
        "\n",
        "#for i in range(99):\n",
        "#  #len([token.lex_id for token in doc[i]])\n",
        "#  Words_vec[i,:len([token.lex_id for token in doc[i]])]=[token.lex_id for token in doc[i]]\n",
        "#  for token in doc[i]:\n",
        "#    #print(token.text, token.has_vector, token.vector, token.vector_norm ,\"\\n\")\n",
        "#    #print(token.text, token.has_vector, token.lex_id ,\"\\n\")\n",
        "#    Words.append(token.text.lower())\n",
        "#    Words_id.append(token.lex_id)\n",
        "\n",
        "    \n",
        "\n",
        "#Vocab = []\n",
        "#Vocab_id = []\n",
        "#[Vocab.append(x) for x in Words if x not in Vocab]\n",
        "#[Vocab_id.append(id) for id in Words_id if id not in Vocab_id]\n",
        "\n",
        "#print('number of unique words in our data=',len(Vocab))\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "class Vocabulary:\n",
        "    PAD_token = 0   # Used for padding short sentences\n",
        "    SOS_token = 1   # Start-of-sentence token\n",
        "    EOS_token = 2   # End-of-sentence token\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {}#{PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 0\n",
        "        self.num_sentences = 0\n",
        "        self.longest_sentence = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            # First entry of word into vocabulary\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            # Word exists; increase word count\n",
        "            self.word2count[word] += 1\n",
        "            \n",
        "    def add_sentence(self, sentence):\n",
        "        sentence_len = 0\n",
        "        for word in [token.text for token in sentence]:\n",
        "            sentence_len += 1\n",
        "            self.add_word(word)\n",
        "        if sentence_len > self.longest_sentence:\n",
        "            # This is the longest sentence\n",
        "            self.longest_sentence = sentence_len\n",
        "        # Count the number of sentences\n",
        "        self.num_sentences += 1\n",
        "\n",
        "    def to_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def to_index(self, word):\n",
        "        return self.word2index[word]\n",
        "\n",
        "voc=Vocabulary('test')\n",
        "for sent in doc:\n",
        "  voc.add_sentence(sent)\n",
        "\n",
        "print('Token 2 corresponds to token:', voc.to_word(2))\n",
        "print('Token \"the\" corresponds to index:', voc.to_index('the'))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token 2 corresponds to token: of\n",
            "Token \"the\" corresponds to index: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhcciczvd5QA"
      },
      "source": [
        "Input_list=[]\n",
        "for sample in range(len(doc)):\n",
        "#  Input_list.append([token.rank for token in doc[sample]])\n",
        "   Input_list.append([voc.to_index(token.text) for token in doc[sample]])\n",
        "Output_list=Input_list;\n",
        "Input_Output_Data_list=[Input_list,Output_list]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuanLbDSMRLp",
        "outputId": "908ab5e8-3695-42b0-e4cb-30f553f5e350"
      },
      "source": [
        "print(Input_list[6],doc[6])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[219, 16, 418, 60, 27, 89, 0, 419, 105, 27, 40, 0, 103, 159, 0, 9, 420, 2, 3, 27, 421, 182, 89, 0, 422, 423, 424, 0, 425, 2, 9, 204, 38, 426, 18, 427, 417, 422, 428, 4, 3, 429, 18, 9, 428, 4, 3, 430, 16, 431, 19, 0, 428, 4, 3, 420, 432, 18, 9, 40, 0, 106, 433, 74, 0, 420, 2, 3, 27, 130, 2, 422, 87, 9, 434, 94, 358, 27, 38, 130, 2, 422, 435, 38, 87, 436, 301, 9, 435, 38, 87, 18] it is assumed that, in the primordial plasma, at the temperatures above the\n",
            "mass of electron, fermions are in the neutral state being the superposition of\n",
            "particle and antiparticle. there exists neutral proton-electron symmetry.\n",
            "proton-electron equilibrium is defined by the proton-electron mass difference.\n",
            "at the temperature equal to the mass of electron, pairs of neutral electrons\n",
            "annihilate into photons, and pairs of neutral protons and electrons survive as\n",
            "protons and electrons.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crgSghzkWfaM"
      },
      "source": [
        "## next: to understand / complete\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#10% test set\n",
        "In_train, In_test, Out_train, Out_test = train_test_split(Input_list, Output_list, test_size=0.1, random_state=1)\n",
        "\n",
        "#from 90% train set --> 20% validation and 80 % training (= in total we have 10% test, 18% val, 72% train )\n",
        "In_train, In_val, Out_train, Out_val = train_test_split(In_train, Out_train , test_size=0.2, random_state=1)\n",
        "\n",
        "train_list=  In_train\n",
        "label=Out_train\n",
        "validation_list=In_val\n",
        "test_list=In_test"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkIqD548dHjO",
        "outputId": "fe1c5600-0ad6-4975-f911-d7ff2347431f"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for _sample in batch:\n",
        "        label_list.append(torch.tensor(_sample))\n",
        "        text_list.append(torch.tensor(_sample))\n",
        "    return pad_sequence(label_list, padding_value=0.0), pad_sequence(text_list, padding_value=0.0)\n",
        "\n",
        "batch_size = 30\n",
        "\n",
        "def create_iterators(batch_size=batch_size):\n",
        "    \"\"\"Heler function to create the iterators\"\"\"\n",
        "    dataloaders = []\n",
        "    for split in [train_list, validation_list, test_list]:\n",
        "        dataloader = DataLoader(\n",
        "            split, batch_size=batch_size,\n",
        "            collate_fn=collate_batch\n",
        "            )\n",
        "        dataloaders.append(dataloader)\n",
        "    return dataloaders\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = create_iterators()\n",
        "\n",
        "next(iter(train_iterator))\n",
        "\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  78,    0, 4038,  ..., 2990,   49,  457],\n",
              "         [5689,    3,   67,  ..., 1720,  205,    4],\n",
              "         [  16,    4,  557,  ..., 1987, 1029,  556],\n",
              "         ...,\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              " tensor([[  78,    0, 4038,  ..., 2990,   49,  457],\n",
              "         [5689,    3,   67,  ..., 1720,  205,    4],\n",
              "         [  16,    4,  557,  ..., 1987, 1029,  556],\n",
              "         ...,\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKin5JYy7J5m",
        "outputId": "791ba7a0-008b-44b5-e4c6-18db2dcc9db7"
      },
      "source": [
        "next(iter(valid_iterator))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  49,   49,    0,  ...,    0, 1017,   49],\n",
              "         [1108,  266, 1325,  ..., 2792, 1099,  287],\n",
              "         [   0,   78,    2,  ..., 1288, 1171,   78],\n",
              "         ...,\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0]]),\n",
              " tensor([[  49,   49,    0,  ...,    0, 1017,   49],\n",
              "         [1108,  266, 1325,  ..., 2792, 1099,  287],\n",
              "         [   0,   78,    2,  ..., 1288, 1171,   78],\n",
              "         ...,\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0],\n",
              "         [   0,    0,    0,  ...,    0,    0,    0]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBhvp2gOw9nN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24a6453-8b9d-4e6c-83fa-e60643fa109f"
      },
      "source": [
        "print(Input_list[6],doc[6])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[219, 16, 418, 60, 27, 89, 0, 419, 105, 27, 40, 0, 103, 159, 0, 9, 420, 2, 3, 27, 421, 182, 89, 0, 422, 423, 424, 0, 425, 2, 9, 204, 38, 426, 18, 427, 417, 422, 428, 4, 3, 429, 18, 9, 428, 4, 3, 430, 16, 431, 19, 0, 428, 4, 3, 420, 432, 18, 9, 40, 0, 106, 433, 74, 0, 420, 2, 3, 27, 130, 2, 422, 87, 9, 434, 94, 358, 27, 38, 130, 2, 422, 435, 38, 87, 436, 301, 9, 435, 38, 87, 18] it is assumed that, in the primordial plasma, at the temperatures above the\n",
            "mass of electron, fermions are in the neutral state being the superposition of\n",
            "particle and antiparticle. there exists neutral proton-electron symmetry.\n",
            "proton-electron equilibrium is defined by the proton-electron mass difference.\n",
            "at the temperature equal to the mass of electron, pairs of neutral electrons\n",
            "annihilate into photons, and pairs of neutral protons and electrons survive as\n",
            "protons and electrons.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AolSQ__6D5Y"
      },
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IokyuWyL6E_b"
      },
      "source": [
        "ntokens = (voc.num_words)#max(Vocab_id) # the size of vocabulary\n",
        "device='cpu'\n",
        "emsize = 200 # embedding dimension\n",
        "nhid = 200 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2 # the number of heads in the multiheadattention models\n",
        "dropout = 0.2 # the dropout value\n",
        "bptt=35\n",
        "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_KSFqEm6ZJD"
      },
      "source": [
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0 # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "train_data=In_train\n",
        "\n",
        "def train():\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, len(train_data) - 1, bptt)):\n",
        "        train_iterator, valid_iterator, test_iterator = create_iterators()\n",
        "        data, targets=next(iter(train_iterator))\n",
        "        optimizer.zero_grad()\n",
        "        if data.size(0) != bptt:\n",
        "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets.view(-1))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            train_iterator, valid_iterator, test_iterator = create_iterators()\n",
        "            data, targets=next(iter(valid_iterator))\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets.view(-1)).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QMNU7Ht6g4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56c58d0f-bf9a-497d-dd9b-e964b9f3a69e"
      },
      "source": [
        "best_val_loss = float(\"inf\")\n",
        "epochs = 100 # The number of epochs\n",
        "best_model = None\n",
        "\n",
        "val_data, targets =next(iter(valid_iterator))\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train()\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 133.68s | valid loss 10.98 | valid ppl 58458.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 132.24s | valid loss 10.67 | valid ppl 43187.82\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gugG0YQM9Ejh"
      },
      "source": [
        "##Generating..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTD4klY0_Lz4"
      },
      "source": [
        "next(iter(train_iterator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6qo2jIUDi7A"
      },
      "source": [
        "#test1= torch.as_tensor([4,5,7,1,81])\n",
        "\n",
        "def generate(model, data_source):\n",
        "    model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            train_iterator, valid_iterator, test_iterator = create_iterators()\n",
        "            data, targets=next(iter(valid_iterator))\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = model(data, src_mask)\n",
        "    return output\n",
        "\n",
        "test11, targets=next(iter(test_iterator))\n",
        "test1=test11[1]#.tolist()\n",
        "generate(model,test1)\n",
        "\n",
        "src_mask=model.generate_square_subsequent_mask(test1.size(0)).to(device)\n",
        "print(model.forward(test1,src_mask).shape)\n",
        "#print(torch.argmax(model.forward(test1,src_mask),dim=2))\n",
        "out=torch.argmax(model.forward(test1,src_mask),dim=2)\n",
        "print([voc.to_word(index) for index in targets[1].tolist()])\n",
        "print([voc.to_word(index) for index in out[4].tolist()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isc5r5s-zrYx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqoVEWy8F5n2"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAwOhMvHIq6m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}